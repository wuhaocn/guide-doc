<div id="cnblogs_post_body" class="blogpost-body"><h3>同步首发：<a href="http://www.yuanrengu.com/index.php/2017-01-17.html" target="_blank">http://www.yuanrengu.com/index.php/2017-01-17.html</a></h3>
<h3>如果你去面试，面试官不问你这个问题，你来找我^_^</h3>
<p><span style="font-size: 16px;">下面直接来干货，先说这三个Map的区别：</span></p>
<h3 id="HashTable"><span style="font-size: 16px;"><strong>HashTable</strong></span></h3>
<ul>
<li><span style="font-size: 16px;">底层数组+链表实现，无论key还是value都<strong>不能为null</strong>，线程<strong>安全</strong>，实现线程安全的方式是在修改数据时锁住整个HashTable，效率低，ConcurrentHashMap做了相关优化</span></li>
<li><span style="font-size: 16px;">初始size为<strong>11</strong>，扩容：newsize = olesize*2+1</span></li>
<li><span style="font-size: 16px;">计算index的方法：index = (hash &amp; 0x7FFFFFFF) % tab.length</span></li>
</ul>
<h3 id="HashMap"><span style="font-size: 16px;"><strong>HashMap</strong></span></h3>
<ul>
<li><span style="font-size: 16px;">底层数组+链表实现，可<strong>以存储null键和null值</strong>，线程<strong>不安全</strong></span></li>
<li><span style="font-size: 16px;">初始size为<strong>16</strong>，扩容：newsize = oldsize*2，size一定为2的n次幂</span></li>
<li><span style="font-size: 16px;">扩容针对整个Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入</span></li>
<li><span style="font-size: 16px;">插入元素后才判断该不该扩容，有可能无效扩容（插入后如果扩容，如果没有再次插入，就会产生无效扩容）</span></li>
<li><span style="font-size: 16px;">当Map中元素总数超过Entry数组的75%，触发扩容操作，为了减少链表长度，元素分配更均匀</span></li>
<li><span style="font-size: 16px;">计算index方法：index = hash &amp; (tab.length – 1)</span></li>
</ul>
<p>&nbsp;</p>
<p><span style="font-size: 16px;">HashMap的初始值还要考虑加载因子:</span></p>
<ul>
<li>&nbsp;<strong style="font-size: 16px; font-family: 'Courier New';">哈希冲突</strong><span style="font-size: 16px; font-family: 'Courier New';">：若干Key的哈希值按数组大小取模后，如果落在同一个数组下标上，将组成一条Entry链，对Key的查找需要遍历Entry链上的每个元素执行equals()比较。</span></li>
<li><span style="font-size: 16px;"><strong>加载因子</strong>：为了降低哈希冲突的概率，默认当HashMap中的键值对达到数组大小的75%时，即会触发扩容。因此，如果预估容量是100，即需要设定100/0.75＝134的数组大小。</span></li>
<li><em id="__mceDel"><span style="font-size: 16px;"><strong>空间换时间</strong>：如果希望加快Key查找的时间，还可以进一步降低加载因子，加大初始大小，以降低哈希冲突的概率。</span></em></li>
</ul>
<p><span style="font-size: 16px;">HashMap和Hashtable都是用hash算法来决定其元素的存储，因此HashMap和Hashtable的hash表包含如下属性：</span></p>
<ul>
<li><span style="font-size: 16px;">容量（capacity）：hash表中桶的数量</span></li>
<li><span style="font-size: 16px;">初始化容量（initial capacity）：创建hash表时桶的数量，HashMap允许在构造器中指定初始化容量</span></li>
<li><span style="font-size: 16px;">尺寸（size）：当前hash表中记录的数量</span></li>
<li><span style="font-size: 16px;">负载因子（load factor）：负载因子等于“size/capacity”。负载因子为0，表示空的hash表，0.5表示半满的散列表，依此类推。轻负载的散列表具有冲突少、适宜插入与查询的特点（但是使用Iterator迭代元素时比较慢）</span></li>
</ul>
<p><span style="font-size: 16px;">除此之外，hash表里还有一个“负载极限”，“负载极限”是一个0～1的数值，“负载极限”决定了hash表的最大填满程度。当hash表中的负载因子达到指定的“负载极限”时，hash表会自动成倍地增加容量（桶的数量），并将原有的对象重新分配，放入新的桶内，这称为rehashing。</span></p>
<p><span style="font-size: 16px;">HashMap和Hashtable的构造器允许指定一个负载极限，HashMap和Hashtable默认的“负载极限”为0.75，这表明当该hash表的3/4已经被填满时，hash表会发生rehashing。</span></p>
<p><span style="font-size: 16px;">“负载极限”的默认值（0.75）是时间和空间成本上的一种折中：</span></p>
<ul>
<li><span style="font-size: 16px;">较高的“负载极限”可以降低hash表所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的操作（HashMap的get()与put()方法都要用到查询）</span></li>
<li><span style="font-size: 16px;">较低的“负载极限”会提高查询数据的性能，但会增加hash表所占用的内存开销</span></li>
</ul>
<p><span style="font-size: 16px;">程序猿可以根据实际情况来调整“负载极限”值。</span></p>
<h3 id="ConcurrentHashMap"><span style="font-size: 16px;"><strong>ConcurrentHashMap</strong></span></h3>
<ul>
<li><span style="font-size: 16px;">底层采用分段的数组+链表实现，线程<strong>安全</strong></span></li>
<li><span style="font-size: 16px;">通过把整个Map分为N个Segment，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。(读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。)</span></li>
<li><span style="font-size: 16px;">Hashtable的synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术</span></li>
<li><span style="font-size: 16px;">有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁</span></li>
<li><span style="font-size: 16px;">扩容：段内扩容（段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容），插入前检测需不需要扩容，有效避免无效扩容</span></li>
</ul>
<p><span style="font-size: 16px;">&nbsp;</span></p>
<p><span style="font-size: 16px;">Hashtable和HashMap都实现了Map接口，但是Hashtable的实现是基于Dictionary抽象类的。Java5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。</span></p>
<p><span style="font-size: 16px;">HashMap基于哈希思想，实现对数据的读写。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，然后找到bucket位置来存储值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞时，对象将会储存在链表的下一个节点中。HashMap在每个链表节点中储存键值对对象。当两个不同的键对象的hashcode相同时，它们会储存在同一个bucket位置的链表中，可通过键对象的equals()方法来找到键值对。如果链表大小超过阈值（TREEIFY_THRESHOLD,8），链表就会被改造为树形结构。</span></p>
<p><span style="font-size: 16px;">在HashMap中，null可以作为键，这样的键只有一个，但可以有一个或多个键所对应的值为null。<strong>当get()方法返回null值时，即可以表示HashMap中没有该key，也可以表示该key所对应的value为null</strong>。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个key，应该用<strong>containsKey()</strong>方法来判断。而在Hashtable中，无论是key还是value都不能为null。</span></p>
<p><span style="font-size: 16px;">Hashtable是线程安全的，它的方法是同步的，可以直接用在多线程环境中。而HashMap则不是线程安全的，在多线程环境中，需要手动实现同步机制。</span></p>
<p><span style="font-size: 16px;">Hashtable与HashMap另一个区别是HashMap的迭代器（Iterator）是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。</span></p>
<p><span style="font-size: 16px;">先看一下简单的类图：</span></p>
<p align="center"><span style="font-size: 16px;"><img src="http://dl2.iteye.com/upload/attachment/0087/3840/1a20c1a7-c422-374b-9acf-8c33479586cb.jpg" alt="" width="717" height="596" data-bd-imgshare-binded="1"></span></p>
<p align="center"><span style="font-size: 16px;">&nbsp;&nbsp;</span></p>
<p align="left"><span style="font-size: 16px;">从类图中可以看出来在存储结构中ConcurrentHashMap比HashMap多出了一个类Segment，而Segment是一个可重入锁。</span></p>
<p align="left"><span style="font-size: 16px;">ConcurrentHashMap是使用了锁分段技术来保证线程安全的。</span></p>
<p align="left"><span style="font-size: 16px;"><strong>锁分段技术</strong>：首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。&nbsp;</span></p>
<p align="left"><span style="font-size: 16px;">ConcurrentHashMap提供了与Hashtable和SynchronizedMap不同的锁机制。Hashtable中采用的锁机制是一次锁住整个hash表，从而在同一时刻只能由一个线程对其进行操作；而ConcurrentHashMap中则是一次锁住一个桶。</span></p>
<p align="left"><span style="font-size: 16px;">ConcurrentHashMap默认将hash表分为16个桶，诸如get、put、remove等常用操作只锁住当前需要用到的桶。这样，原来只能一个线程进入，现在却能同时有16个写线程执行，并发性能的提升是显而易见的。</span></p>
<p><span style="font-size: 16px;">&nbsp;</span></p></div>

参考：
https://www.cnblogs.com/heyonggang/p/9112731.html
