1. 字符串子串查找算法 KMP

给定一个主串（以 S 代替）和模式串（以 P 代替），要求找出 P 在 S 中出现的位置，此即串的模式匹配问题。

Knuth-Morris-Pratt 算法（简称 KMP）是解决这一问题的常用算法之一，这个算法是由高德纳（Donald Ervin Knuth）和沃恩·普拉特在 1974 年构思，同年詹姆斯·H·莫里斯也独立地设计出该算法，最终三人于 1977 年联合发表。

KMP 算法与其他字符串子串查找的典型的区别是它先计算子串本身存在的一些相关信息，这样可以保证每次匹配不用从最开始位置查找，而是从最佳的位置开始匹配，从而提高了查找的效率，保证复杂度在 O(n+m)规模。KMP 算法的精华部分就在于求模式匹配的 next 数组，如果对状态机有所了解，就能很好的理解这一思想。

由于关于 KMP 算法网上有很多经典的的介绍，这里就不详细讨论，只给出算法实现。

代码实现：

class Solution: def getnext(self,needle): needleLen=len(needle) next=[-1]/\*needleLen i,k=0,-1 while i

2.最长连续公共子序列

![](https://ask.qcloudimg.com/http-save/developer-news/uwwijonlxi.jpeg?imageView2/2/w/1620)

要求两个字符串的最长连续公共子序列，一般采用的方法是后缀数组法，即先分别求出两个串的后缀数组，然后比较它们之间的连续公共长度。这个有个处理技巧就是为了确认哪个后缀数组属于哪个串，需要在其中一个串后面贴一个标签，避免混淆。

当然另一种是使用动态规划进行求解，因此求出问题的状态转移方程至关重要。下面是求解最长连续公共子序列的状态转移方程，知道了状态转移方程，求解就变得很简单了。

代码实现：

class Solution: def ConsecutiveLCS(self,s1,s2): s1Len=len(s1) s2Len=len(s2) arr=[[0]/\*(s2Len+1) for i in range(s1Len+1)] res=0 for i in range(1,s1Len+1): for j in range(1,s2Len+1): if s1[i-1]==s2[j-1]: arr[i][j]=arr[i-1][j-1]+1 if res

3.最长公共子序列

要求两个串的公共子序列，则这些子序列不一定是连续的，如下图所示。

![](https://ask.qcloudimg.com/http-save/developer-news/puhzn0wzub.jpeg?imageView2/2/w/1620)

对于这类问题通常的解法是采用动态规划，状态转移方程如下所示。

代码实现：

class Solution: def LCS(self,s1,s2): s1Len=len(s1) s2Len=len(s2) arr=[[0]/\*(s2Len+1) for i in range(s1Len+1)] for i in range(1,s1Len+1): for j in range(1,s2Len+1): if s1[i-1]==s2[j-1]: arr[i][j]=arr[i-1][j-1]+1 else: arr[i][j]=max(arr[i-1][j],arr[i][j-1]) return arr[s1Len][s2len]

4.字符串模糊匹配（状态机）

对字符串进行模糊匹配查找，我们通常采用的是正则表达式实现。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。

而如何判断一个字符串与当前的正则表达式匹配，一般是将一个正则表达式转化为一个状态机。当当前的字符串在匹配过程中进入一个可接受状态，则称之为匹配成功。

正则表达式 a(bb)+a 的状态转移图

每一个正则表达式都有一个对应的有限状态机。然而这个对应的有限状态机可能是确定的，也可能是非确定的。非确定状态机和确定状态机的区别是对于一个接收符号是否有唯一的离开路径，如果离开路径唯一则是确定的，否则为非确定的。对于非确定有限状态机（如下图所示），一般存在多路径匹配，而对于确定有限状态机（如上图所示）则不会。

非确定状态机多路径匹配

因此，如果对非确定有限状态机不想采用多路径匹配，一种通常的处理思路是采用子集构造算法将非确定状态机转为有限状态机。由于涉及的相关知识较多，有兴趣可以参阅相关正则表达式算法实现或者词法分析进行详细了解。

例：判断一个字符串是否是一个实数。

测试样例：

"0" => true" 0.1 " => true"abc" => false"1 a" => false"2e10" => true

分析：根据题意，可以写出实数判定的正则表达式：(\s/_)[+-]?((\.[0-9]+)|([0-9]+(\.[0-9]/_)?))(e[+-]?[0-9]+)?(\s/\*)。然后将它转为一个状态机进行求解，如下图所示。

![](https://ask.qcloudimg.com/http-save/developer-news/kjcq20zt8l.jpeg?imageView2/2/w/1620)

除了字符串匹配、查找回文串、查找重复子串等经典问题以外，日常生活中我们还会遇到其它一些怪异的字符串问题。比如，有时我们需要知道给定的两个字 符串“有多像”，换句话说两个字符串的相似度是多少。1965 年，俄国科学家 VladimirLevenshtein 给字符串相似度做出了一个明确的定义 叫做 Levenshtein 距离，我们通常叫它“编辑距离”。字符串 A 到 B 的编辑距离是指，只用插入、删除和替换三种操作，最少需要多少步可以把 A 变成 B。例如，从 FAME 到 GATE 需要两步（两次替换），从 GAME 到 ACM 则需要三步（删除 G 和 E 再添加 C）。Levenshtein 给出了编辑距离的一 般求法，就是大家都非常熟悉的经典动态规划问题。

在自然语言处理中，这个概念非常重要，例如我们可以根据这个定义开发出一套半自动的校对系统：查找出一篇文章里所有不在字典里的单词，然后对于每个单词， 列出字典里与它的 Levenshtein 距离小于某个数 n 的单词，让用户选择正确的那一个。n 通常取到 2 或者 3，或者更好地，取该单词长度的 1/4 等等。 这个想法倒不错，但算法的效率成了新的难题：查字典好办，建一个 Trie 树即可；但怎样才能快速在字典里找出最相近的单词呢？这个问题难就难 在，Levenshtein 的定义可以是单词任意位置上的操作，似乎不遍历字典是不可能完成的。现在很多软件都有拼写检查的功能，提出更正建议的速度是很 快的。它们到底是怎么做的呢？1973 年，Burkhard 和 Keller 提出的 BK 树有效地解决了这个问题。这个数据结构强就强在，它初步解决了一个看 似不可能的问题，而其原理非常简单。

首先，我们观察 Levenshtein 距离的性质。令 d(x,y)表示字符串 x 到 y 的 Levenshtein 距离，那么显然：

1. d(x,y) = 0 当且仅当 x=y （Levenshtein 距离为 0 <==> 字符串相等）

2. d(x,y) = d(y,x) （从 x 变到 y 的最少步数就是从 y 变到 x 的最少步数）

3. d(x,y) + d(y,z) >= d(x,z) （从 x 变到 z 所需的步数不会超过 x 先变成 y 再变成 z 的步数）

最后这一个性质叫做三角形不等式。就好像一个三角形一样，两边之和必然大于第三边。给某个集合内的元素定义一个二元的“距离函数”，如果这个距离函数同时 满足上面说的三个性质，我们就称它为“度量空间”。我们的三维空间就是一个典型的度量空间，它的距离函数就是点对的直线距离。度量空间还有很多，比如 Manhattan 距离，图论中的最短路，当然还有这里提到的 Levenshtein 距离。就好像并查集对所有等价关系都适用一样，BK 树可以用于任何一 个度量空间。

建树的过程有些类似于 Trie。首先我们随便找一个单词作为根（比如 GAME）。以后插入一个单词时首先计算单词与根的 Levenshtein 距离：如果 这个距离值是该节点处头一次出现，建立一个新的儿子节点；否则沿着对应的边递归下去。例如，我们插入单词 FAME，它与 GAME 的距离为 1，于是新建一个 儿子，连一条标号为 1 的边；下一次插入 GAIN，算得它与 GAME 的距离为 2，于是放在编号为 2 的边下。再下次我们插入 GATE，它与 GAME 距离为 1， 于是沿着那条编号为 1 的边下去，递归地插入到 FAME 所在子树；GATE 与 FAME 的距离为 2，于是把 GATE 放在 FAME 节点下，边的编号为 2。

查询操作异常方便。如果我们需要返回与错误单词距离不超过 n 的单词，这个错误单词与树根所对应的单词距离为 d，那么接下来我们只需要递归地考虑编号在 d-n 到 d+n 范围内的边所连接的子树。由于 n 通常很小，因此每次与某个节点进行比较时都可以排除很多子树。

举个例子，假如我们输入一个 GAIE，程序发现它不在字典中。现在，我们想返回字典中所有与 GAIE 距离为 1 的单词。我们首先将 GAIE 与树根进行比较， 得到的距离 d=1。由于 Levenshtein 距离满足三角形不等式，因此现在所有离 GAME 距离超过 2 的单词全部可以排除了。比如，以 AIM 为根的子树 到 GAME 的距离都是 3，而 GAME 和 GAIE 之间的距离是 1，那么 AIM 及其子树到 GAIE 的距离至少都是 2。于是，现在程序只需要沿着标号范围在 1-1 到 1+1 里的边继续走下去。我们继续计算 GAIE 和 FAME 的距离，发现它为 2，于是继续沿标号在 1 和 3 之间的边前进。遍历结束后回到 GAME 的第 二个节点，发现 GAIE 和 GAIN 距离为 1，输出 GAIN 并继续沿编号为 1 或 2 的边递归下去（那条编号为 4 的边连接的子树又被排除掉了）……

实践表明，一次查询所遍历的节点不会超过所有节点的 5%到 8%，两次查询则一般不会 17-25%，效率远远超过暴力枚举。适当进行缓存，减小 Levenshtein 距离常数 n 可以使算法效率更高。

5.编辑距离算法

编辑距离，又称 Levenshtein 距离（莱文斯坦距离也叫做 Edit Distance），是指两个字串之间，由一个转成另一个所需的最少编辑操作次数，如果它们的距离越大，说明它们越是不同。许可的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。

在概念中，我们可以看出一些重点那就是，编辑操作只有三种。插入，删除，替换这三种操作，我们有两个字符串，将其中一个字符串经过上面的这三种操作之后，得到两个完全相同的字符串付出的代价是什么就是我们要讨论和计算的。在这里我们设置每经过一次编辑，也就是变化（插入，删除，替换）我们花费的代价都是 1。

编辑距离的作用主要是用来比较两个字符串的相似度的。

对于这类问题，我们可以采用动态规划进行解决：用 f[m-1,n]+1 表示增加操作，f[m,n-1]+1 表示我们的删除操作，f[m-1,n-1]+temp（str1[i] == str2[j]，用 temp 记录它，为 0；否则 temp 记为 1）表示我们的替换操作。状态转移方程为：

通过上面的介绍我们可以用矩阵求两个字符串的最小编辑距离了，但是这么做的原理是什么呢？其实很简单，当我们要求字符串 s[1...i]到 t[1...j]的编辑距离的时候：

1. 如果我们知道可以在 k1 个操作内将 s[1...i-1]转换为 t[1...j]，那么用 k1+1 次操作一定能将 s[1...i]转化为 t[1...j]，因为只需要先做一次移除操作移除 s[i]将 s[1...i]转化为 s[1...i-1]，然后再做 k1 个操作就可以转换为 t[1...j]。
1. 如果我们知道可以在 k2 个操作内将 s[1...i]转换为 t[1...j-1]，那么用 k2+1 次操作一定能将 s[1...i]转化为 t[1...j]，因为我们可以先用 k2 次操作将 s[1...i]转化为 t[1...j-1]，然后再执行一次插入操作在末尾插入 t[j]即可将 s[1...i]转化为 t[1...j]
1. 如果我们知道可以在 k3 个操作内将 s[1...i-1]转化为 t[1...j-1]，那么如果 s[i]==t[j]，则将 s[1...i]转换为 t[1...j]只需要 k3 次操作，如果 s[i]!=t[j]，则需要做一次替换操作将 s[i]替换为 t[j]，这种情况下需要 k3+1 次操作。

而上面我们讨论的 3 中情况下的 k1、k2、k3 就对应着矩阵里一个单元格的左、上、左上的单元格里的值。

上述结论可以表述为如下公式：

![](https://images2015.cnblogs.com/blog/777853/201703/777853-20170322111502783-1370496412.png)

#

明白了原理之后，写代码很简单，就是用代码模拟计算矩阵的过程(java 实现)，时间复杂度是 O(|s1|/\*|s2|) (|s1|、|s2|分别代表字符串 s1 和 s2 的长度)：
[![复制代码](https://common.cnblogs.com/images/copycode.gif)]("复制代码")

```
package common; import org.junit.Assert; public class LevenshteinDistance { public static int getDistance(String src, String des) { int[][] m=new int[des.length()+1][]; for (int i = 0; i < m.length; i++) { m[i]=new int[src.length()+1]; } for(int i=0;i<src.length()+1;i++){ m[0][i]=i; } for(int i=0;i<des.length()+1;i++){ m[i][0]=i; } for(int i=1;i<des.length()+1;i++){ for (int j = 1; j < src.length()+1; j++) { int rcost=des.charAt(i-1)==src.charAt(j-1)?0:1; m[i][j]=Math.min(Math.min(m[i-1][j]+1, m[i-1][j-1]+rcost), m[i][j-1]+1); } } return m[des.length()][src.length()]; } public static void main(String[] args) { Assert.assertEquals(getDistance("cat", "dog"), 3); //replace Assert.assertEquals(getDistance("cat", "cbt"), 1); //replace Assert.assertEquals(getDistance("cat", "ca"), 1); //delete Assert.assertEquals(getDistance("catx", "cat"), 1); //delete Assert.assertEquals(getDistance("ct", "cat"), 1); //insert Assert.assertEquals(getDistance("xcat", "caty"), 2); //delete and insert Assert.assertEquals(getDistance("fast", "cats"), 3); Assert.assertEquals(getDistance("cats", "fast"), 3); Assert.assertEquals(getDistance("kitten", "sitting"), 3); Assert.assertEquals(getDistance("sitting", "kitten"), 3); Assert.assertEquals(getDistance("jary", "jerry"), 2); Assert.assertEquals(getDistance("jerry", "jary"), 2); } }
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)]("复制代码")

要学会编辑距离算法主要就是掌握两点，第一是要会通过矩阵手算两个字符串的编辑距离，第二就是明白为什么可以这么计算。掌握了这两点写程序就很简单了。

参考：

[https://cloud.tencent.com/developer/news/253531](https://cloud.tencent.com/developer/news/253531)

[https://www.cnblogs.com/sheeva/p/6598449.html](https://www.cnblogs.com/sheeva/p/6598449.html)

https://blog.csdn.net/eric509/article/details/84804235
